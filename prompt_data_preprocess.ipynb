{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca84be-46b8-4f3a-99f9-b29f8758e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch \n",
    "import json\n",
    "import pandas as pd\n",
    "from ResearchGraphDataset import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575b654-3526-4a56-8e46-30d6c83da274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/utils/generic.py:353: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Processing papers: 100%|██████████| 12209/12209 [00:01<00:00, 6290.17it/s]\n",
      "Processing collaborations: 12209it [00:01, 11373.10it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('df.json') \n",
    "df = df[df['publication_year']>=2020]\n",
    "\n",
    "with open('splits_New.pkl', 'rb') as f: # 划分文件 \n",
    "\tsplits = pickle.load(f)\n",
    "\n",
    "with open( f'train_samples_2023_Original.pkl', 'rb') as f: # 获取的最优样本\n",
    "    best_sample = pickle.load(f)\n",
    "\n",
    "dataset = ResearchGraphDataset(df,splits, max_authors = 2) \n",
    "dataset.splits = splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "392cf4b8-fa7c-4a70-8e8a-1bc873da1543",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e538b72-4982-49ba-9acb-487c3e3a1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3441efc5-fe09-40ea-a1fd-1d840140cddb",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7311f2-90f3-4b09-aab7-f1744fe2f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(graph: dgl.DGLGraph, target_pair: tuple) -> list:\n",
    "    \"\"\"获取目标节点对的二跳邻居ID集合\"\"\"\n",
    "    a, b = target_pair\n",
    "\n",
    "    a_subg = dgl.khop_in_subgraph(graph, a, k=2)[0]\n",
    "    b_subg = dgl.khop_in_subgraph(graph, b, k=2)[0]\n",
    "\n",
    "    a_neighbors = set(a_subg.ndata[dgl.NID].tolist())\n",
    "    b_neighbors = set(b_subg.ndata[dgl.NID].tolist())\n",
    "    return sorted(a_neighbors- {b}, key=lambda x: (len(str(x)), str(x))),sorted(b_neighbors- {a}, key=lambda x: (len(str(x)), str(x)))\n",
    "\n",
    "def generate_focused_graph_desc(, graph: dgl.DGLGraph, target_pair: tuple) -> str:\n",
    "    #初始化\n",
    "    a_id, b_id = target_pair\n",
    "    current_year = graph.edata['year'].max().item() \n",
    "    active_authors,author_id_to_idx,idx_to_author_id = dataset.generate_authorid2idx(current_year)\n",
    "    a_idx,b_idx = author_id_to_idx[a_id],author_id_to_idx[b_id]\n",
    "    desc = []\n",
    "    #合作情况\n",
    "    collab = dataset.author_metadata[a_id]['collaborators'].get(b_id, 0) # 在a的合作者中寻找b\n",
    "\n",
    "    if collab >= 0:\n",
    "        desc.append(f\"历史合作: 与对方合作{collab}篇\")\n",
    "    else:\n",
    "        desc.append(f\"历史合作: 与对方合作0篇\")\n",
    "\n",
    "    dist_vec = dgl.shortest_dist(graph, root=a_idx)\n",
    "\n",
    "    if dist_vec[b_idx] >0:\n",
    "        desc.append(f\"与对方路径距离: {int(dist_vec[b_idx].item())}跳\")\n",
    "    else:\n",
    "        desc.append(\"与对方路径不可达\")\n",
    "    return \" | \".join(desc)\n",
    "\n",
    "\n",
    "def build_agent_context(graph: dgl.DGLGraph, agent_id: str, current_year: int) -> dict:\n",
    "    '''构建agent的自我认知上下文'''\n",
    "    current_year = graph.edata['year'].max().item() \n",
    "    active_authors,author_id_to_idx,idx_to_author_id = dataset.generate_authorid2idx(current_year)\n",
    "    agent_idx = author_id_to_idx[agent_id]\n",
    "    return {\n",
    "        'degree_centrality': graph.ndata['degree_cent'][agent_idx].item(),\n",
    "        'constraint': graph.ndata['constraint'][agent_idx].item(),\n",
    "        'papers_num': graph.ndata['paper_count'][agent_idx].item(),\n",
    "        'citations': graph.ndata['citations'][agent_idx].item(),\n",
    "        'text': dataset.get_raw_data(agent_id)['raw_text']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958395f0-0f7c-472e-834b-52ff199cffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = dataset.splits[2023]\n",
    "active_authors,author_id_to_idx,idx_to_author_id = dataset.generate_authorid2idx(2023)\n",
    "train_g = dataset._add_topological_features(splits['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8199e02-b3c4-4c63-9551-e073f07f172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [1:14:24<00:00,  2.23s/it]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "current_year=2023\n",
    "\n",
    "active_authors,author_id_to_idx,idx_to_author_id = dataset.generate_authorid2idx(current_year)\n",
    "\n",
    "for src_nodes, dst_nodes, batch_labels in tqdm(best_sample):\n",
    "    info = {}\n",
    "    src_nodes = src_nodes.to(device)\n",
    "    dst_nodes = dst_nodes.to(device)\n",
    "    batch_labels = batch_labels.float().to(device)\n",
    "    key = (src_nodes.item(), dst_nodes.item()) \n",
    "    if key not in data:\n",
    "            try:\n",
    "                a_idx = key[0] if isinstance(key[0], torch.Tensor) else int(key[0])\n",
    "                b_idx = key[1] if isinstance(key[1], torch.Tensor) else int(key[1])\n",
    "                a_id,b_id = idx_to_author_id[a_idx], idx_to_author_id[b_idx]\n",
    "                a_ctx = build_agent_context(train_g,a_id)\n",
    "                b_ctx = build_agent_context(train_g,b_id)\n",
    "                a_neighbors,b_neighbors = get_neighbors(train_g,key)\n",
    "                \n",
    "                info['dist'] = generate_focused_graph_desc(train_g, (a_id,b_id))\n",
    "                info['a_degree_centrality'] = a_ctx['degree_centrality']\n",
    "                info['b_degree_centrality'] = b_ctx['degree_centrality']\n",
    "                info['a_constraint'] = a_ctx['constraint']\n",
    "                info['b_constraint'] = b_ctx['constraint']\n",
    "                info['a_papers_num'] = a_ctx['papers_num']\n",
    "                info['b_papers_num'] = b_ctx['papers_num']\n",
    "                info['a_citations'] = a_ctx['citations']\n",
    "                info['b_citations'] = b_ctx['citations']\n",
    "                info['a_neighbors'] = a_neighbors\n",
    "                info['b_neighbors'] = b_neighbors\n",
    "                info['a_text'] = a_ctx['text']\n",
    "                info['b_text'] = b_ctx['text']\n",
    "            except:\n",
    "                error_list.append(key)\n",
    "                continue\n",
    "            \n",
    "            data[key] = info\n",
    "    else:\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1281d3a5-a093-4241-8cc5-2b5ebf7b260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data= {}\n",
    "for row_key, cols in data.items():\n",
    "    row_str = str(row_key)\n",
    "    for col_key, value in cols.items():\n",
    "        new_data.setdefault(col_key, {})[row_str] = value\n",
    "with open(f'data.json', \"w\") as f:\n",
    "    json.dump(new_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
